{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PySpark XML with XSD Parser",
      "provenance": [],
      "authorship_tag": "ABX9TyMLgOLpQlF36rYEyyU/Kfpj"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8FHbhujUfDB",
        "outputId": "f61b03c9-90b6-491e-9d78-dae5cf7b9db0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ],
      "metadata": {
        "id": "OT8L8TwILvAQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://archive.apache.org/dist/spark/spark-2.4.7/spark-2.4.7-bin-hadoop2.7.tgz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mf-3mA7pL5vN",
        "outputId": "554cd564-c403-4681-8a00-42a2923264be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-07-24 09:56:21--  https://archive.apache.org/dist/spark/spark-2.4.7/spark-2.4.7-bin-hadoop2.7.tgz\n",
            "Resolving archive.apache.org (archive.apache.org)... 138.201.131.134, 2a01:4f8:172:2ec5::2\n",
            "Connecting to archive.apache.org (archive.apache.org)|138.201.131.134|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 233333392 (223M) [application/x-gzip]\n",
            "Saving to: ‘spark-2.4.7-bin-hadoop2.7.tgz’\n",
            "\n",
            "spark-2.4.7-bin-had 100%[===================>] 222.52M  18.5MB/s    in 21s     \n",
            "\n",
            "2022-07-24 09:56:42 (10.6 MB/s) - ‘spark-2.4.7-bin-hadoop2.7.tgz’ saved [233333392/233333392]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xzf /content/spark-2.4.7-bin-hadoop2.7.tgz"
      ],
      "metadata": {
        "id": "L-v__9RML80H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q findspark"
      ],
      "metadata": {
        "id": "0UtLbpd_MBR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.7-bin-hadoop2.7\""
      ],
      "metadata": {
        "id": "TdwKbrj3MDsQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark"
      ],
      "metadata": {
        "id": "Wy81RNhCMFs0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "findspark.init(\"/content/spark-2.4.7-bin-hadoop2.7/\")"
      ],
      "metadata": {
        "id": "rFoSH1liMH8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "findspark.find()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "gLiTZIdLMK_z",
        "outputId": "5bec9f2b-9cc6-400c-d39c-0133c66e950e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/spark-2.4.7-bin-hadoop2.7/'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession \\\n",
        "        .builder \\\n",
        "        .appName(\"CorrelationExample\").config('spark.jars.packages', 'com.databricks:spark-xml_2.11:0.4.1') \\\n",
        "        .getOrCreate()\n",
        "\n",
        "    # .config('spark.jars.packages', 'com.databricks:spark-xml_2.11:0.6.0')\\"
      ],
      "metadata": {
        "id": "O1vgUzlCMO3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sparkContext.getConf().getAll()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54UXx8qo0VNj",
        "outputId": "639c3efe-ed48-4c43-b52a-d4685ddca399"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('spark.driver.host', 'a9dbc39c4b08'),\n",
              " ('spark.submit.pyFiles',\n",
              "  '/root/.ivy2/jars/com.databricks_spark-xml_2.11-0.4.1.jar'),\n",
              " ('spark.app.name', 'CorrelationExample'),\n",
              " ('spark.executor.id', 'driver'),\n",
              " ('spark.app.id', 'local-1658656961598'),\n",
              " ('spark.jars',\n",
              "  'file:///root/.ivy2/jars/com.databricks_spark-xml_2.11-0.4.1.jar'),\n",
              " ('spark.jars.packages', 'com.databricks:spark-xml_2.11:0.4.1'),\n",
              " ('spark.repl.local.jars',\n",
              "  'file:///root/.ivy2/jars/com.databricks_spark-xml_2.11-0.4.1.jar'),\n",
              " ('spark.rdd.compress', 'True'),\n",
              " ('spark.serializer.objectStreamReset', '100'),\n",
              " ('spark.master', 'local[*]'),\n",
              " ('spark.submit.deployMode', 'client'),\n",
              " ('spark.files',\n",
              "  'file:///root/.ivy2/jars/com.databricks_spark-xml_2.11-0.4.1.jar'),\n",
              " ('spark.driver.port', '43737'),\n",
              " ('spark.ui.showConsoleProgress', 'true')]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read \\\n",
        "    .format(\"xml\") \\\n",
        "    .option(\"rowTag\", \"person\") \\\n",
        "    .load(\"/content/drive/MyDrive/test1.xml\")\n"
      ],
      "metadata": {
        "id": "lpGjJu5gJ8Bt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()"
      ],
      "metadata": {
        "id": "ElI-grgAKjtF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20410c7d-cd99-46c3-e652-8d6f7badb14f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- _id: long (nullable = true)\n",
            " |-- addresses: struct (nullable = true)\n",
            " |    |-- address: array (nullable = true)\n",
            " |    |    |-- element: struct (containsNull = true)\n",
            " |    |    |    |-- city: string (nullable = true)\n",
            " |    |    |    |-- state: string (nullable = true)\n",
            " |    |    |    |-- street: string (nullable = true)\n",
            " |-- dob_month: long (nullable = true)\n",
            " |-- dob_year: long (nullable = true)\n",
            " |-- firstname: string (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- lastname: string (nullable = true)\n",
            " |-- middlename: string (nullable = true)\n",
            " |-- salary: struct (nullable = true)\n",
            " |    |-- _VALUE: long (nullable = true)\n",
            " |    |-- _currency: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwnlUtvWpXbR",
        "outputId": "9ece51e6-7307-4e2a-8938-fb039697dbe9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+--------------------+---------+--------+---------+------+--------+----------+---------------+\n",
            "|_id|           addresses|dob_month|dob_year|firstname|gender|lastname|middlename|         salary|\n",
            "+---+--------------------+---------+--------+---------+------+--------+----------+---------------+\n",
            "|  1|[[[NewJersy, NJ, ...|        1|    1980|    James|     M|   Smith|      null|  [10000, Euro]|\n",
            "|  2|[[[new york, NY, ...|        6|    1990|  Michael|     M|    null|      Rose|[10000, Dollor]|\n",
            "+---+--------------------+---------+--------+---------+------+--------+----------+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sparkContext.addFile(\"/content/drive/MyDrive/test1.xsd\")"
      ],
      "metadata": {
        "id": "1aEYjaONtu9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_schema=spark.read.format(\"xml\").option(\"rowTag\",\"Root\").\\\n",
        "option(\"rowValidationXSDPath\",\"test1.xsd\").load(\"/content/drive/MyDrive/test1.xml\")"
      ],
      "metadata": {
        "id": "qFJmq-y_u9wt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVPddAFlvFth",
        "outputId": "aefcd429-ed60-460b-b85f-625e933fff67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- _id: long (nullable = true)\n",
            " |-- addresses: struct (nullable = true)\n",
            " |    |-- address: array (nullable = true)\n",
            " |    |    |-- element: struct (containsNull = true)\n",
            " |    |    |    |-- city: string (nullable = true)\n",
            " |    |    |    |-- state: string (nullable = true)\n",
            " |    |    |    |-- street: string (nullable = true)\n",
            " |-- dob_month: long (nullable = true)\n",
            " |-- dob_year: long (nullable = true)\n",
            " |-- firstname: string (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- lastname: string (nullable = true)\n",
            " |-- middlename: string (nullable = true)\n",
            " |-- salary: struct (nullable = true)\n",
            " |    |-- _VALUE: long (nullable = true)\n",
            " |    |-- _currency: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!/content/spark-2.4.7-bin-hadoop2.7/bin/spark-shell"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hS_Yy2HYvN2L",
        "outputId": "d0e807a3-5460-4ddd-c6d0-9016dc738b4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22/07/24 10:29:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
            "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
            "Setting default log level to \"WARN\".\n",
            "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
            "22/07/24 10:30:09 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
            "Spark context Web UI available at http://a9dbc39c4b08:4041\n",
            "Spark context available as 'sc' (master = local[*], app id = local-1658658609917).\n",
            "Spark session available as 'spark'.\n",
            "Welcome to\n",
            "      ____              __\n",
            "     / __/__  ___ _____/ /__\n",
            "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
            "   /___/ .__/\\_,_/_/ /_/\\_\\   version 2.4.7\n",
            "      /_/\n",
            "         \n",
            "Using Scala version 2.11.12 (OpenJDK 64-Bit Server VM, Java 1.8.0_312)\n",
            "Type in expressions to have them evaluated.\n",
            "Type :help for more information.\n",
            "\n",
            "scala> "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession \\\n",
        "        .builder \\\n",
        "        .appName(\"CorrelationExample\").config('spark.jars.packages', 'com.databricks:spark-xml_2.11:0.4.1') \\\n",
        "        .getOrCreate()"
      ],
      "metadata": {
        "id": "VEnZqgcU46my"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}